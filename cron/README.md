# SystÃ¨me de Scraping Automatique - Culture Radar

## ğŸ“‹ Vue d'ensemble

Ce systÃ¨me permet de rÃ©cupÃ©rer automatiquement les Ã©vÃ©nements culturels depuis plusieurs sources (Google Events, OpenAgenda, etc.) et de les stocker dans une base de donnÃ©es MySQL.

## ğŸš€ Installation

### 1. CrÃ©er la base de donnÃ©es

```bash
mysql -u root -p < setup-database.sql
```

### 2. Configurer le cron job

```bash
chmod +x setup-cron.sh
./setup-cron.sh
```

Cela configurera les tÃ¢ches suivantes :
- **Scraping quotidien** : 6h00 du matin
- **Nettoyage hebdomadaire** : Dimanche 3h00
- **Rapport quotidien** : 9h00 du matin

### 3. Configurer les clÃ©s API

Ã‰diter `/root/culture-radar/config.php` :

```php
define('SERPAPI_KEY', 'votre_clÃ©_serpapi');
define('ADMIN_EMAIL', 'admin@example.com'); // Pour les rapports
```

## ğŸ“ Structure des fichiers

```
cron/
â”œâ”€â”€ scrape-events.php      # Script principal de scraping
â”œâ”€â”€ cleanup.php            # Nettoyage des anciens Ã©vÃ©nements
â”œâ”€â”€ daily-report.php       # GÃ©nÃ©ration du rapport quotidien
â”œâ”€â”€ manual-scrape.php      # Lancement manuel pour tests
â”œâ”€â”€ setup-cron.sh          # Configuration du cron
â”œâ”€â”€ logs/                  # Dossier des logs
â”‚   â”œâ”€â”€ scraping_*.log     # Logs de scraping
â”‚   â”œâ”€â”€ cleanup_*.log      # Logs de nettoyage
â”‚   â””â”€â”€ report_*.log       # Logs des rapports
â””â”€â”€ reports/               # Rapports HTML gÃ©nÃ©rÃ©s
    â””â”€â”€ report_*.html      # Rapports quotidiens
```

## ğŸ”§ Utilisation

### Lancer manuellement le scraping

```bash
# Scrapper toutes les villes
php manual-scrape.php

# Scrapper une ville spÃ©cifique
php manual-scrape.php --city=Paris

# Mode test (sans enregistrer)
php manual-scrape.php --test --verbose

# Aide
php manual-scrape.php --help
```

### Voir les logs

```bash
# Logs en temps rÃ©el
tail -f logs/scraping_*.log

# Derniers logs
cat logs/scraping_$(date +%Y-%m-%d).log
```

### VÃ©rifier le cron

```bash
# Voir les jobs configurÃ©s
crontab -l

# Ã‰diter les jobs
crontab -e

# Voir les logs systÃ¨me du cron
grep CRON /var/log/syslog
```

## ğŸ“Š Base de donnÃ©es

### Tables principales

- **events** : Stockage des Ã©vÃ©nements
- **scraping_logs** : Historique des scraping
- **event_sources** : Sources de donnÃ©es configurÃ©es
- **event_categories** : CatÃ©gories d'Ã©vÃ©nements

### RequÃªtes utiles

```sql
-- Ã‰vÃ©nements du jour
SELECT * FROM events 
WHERE DATE(start_date) = CURDATE() 
AND is_active = 1 
ORDER BY ai_score DESC;

-- Statistiques par ville
SELECT city, COUNT(*) as total 
FROM events 
WHERE is_active = 1 
GROUP BY city;

-- Derniers scraping
SELECT * FROM scraping_logs 
ORDER BY created_at DESC 
LIMIT 10;
```

## ğŸ” Sources de donnÃ©es

### 1. Google Events (SerpAPI)
- **API** : https://serpapi.com/google-events-api
- **Limite** : 100 requÃªtes/mois (plan gratuit)
- **DonnÃ©es** : Ã‰vÃ©nements Google avec lieu, date, prix

### 2. OpenAgenda (Ã€ configurer)
- **API** : https://openagenda.com/api
- **ClÃ© requise** : Demander sur leur site
- **DonnÃ©es** : Ã‰vÃ©nements culturels franÃ§ais

### 3. Eventbrite (Ã€ implÃ©menter)
- **API** : https://www.eventbrite.com/platform/api
- **OAuth requis** : Configuration avancÃ©e

## ğŸ“ˆ Monitoring

### Dashboard de statistiques

CrÃ©er une page PHP pour visualiser :
- Nombre d'Ã©vÃ©nements par jour
- Taux de succÃ¨s du scraping
- Ã‰vÃ©nements populaires
- Couverture par ville

### Alertes

Configurer des alertes email si :
- Le scraping Ã©choue
- Moins de X Ã©vÃ©nements trouvÃ©s
- Erreurs rÃ©pÃ©tÃ©es

## ğŸ› DÃ©pannage

### Le cron ne s'exÃ©cute pas

```bash
# VÃ©rifier que cron est actif
service cron status

# RedÃ©marrer cron
service cron restart

# VÃ©rifier les permissions
chmod +x cron/*.php
```

### Erreurs de base de donnÃ©es

```bash
# VÃ©rifier MySQL
mysql -u root -p -e "SHOW DATABASES;"

# RÃ©parer les tables
mysql -u root -p culture_radar -e "REPAIR TABLE events;"
```

### API rate limiting

- Utiliser plusieurs clÃ©s API
- Espacer les requÃªtes (sleep)
- ImplÃ©menter un cache

## ğŸ“ Maintenance

### TÃ¢ches rÃ©guliÃ¨res

1. **Quotidien** : VÃ©rifier les logs de scraping
2. **Hebdomadaire** : Nettoyer les anciens Ã©vÃ©nements
3. **Mensuel** : Optimiser les tables MySQL
4. **Trimestriel** : Purger les vieux logs

### Commandes utiles

```bash
# Backup de la base
mysqldump -u root -p culture_radar > backup_$(date +%Y%m%d).sql

# Restaurer un backup
mysql -u root -p culture_radar < backup_20240215.sql

# Nettoyer les logs de plus de 30 jours
find logs/ -name "*.log" -mtime +30 -delete
```

## ğŸš€ AmÃ©liorations futures

- [ ] Ajouter plus de sources (Eventbrite, Facebook Events)
- [ ] Machine Learning pour le scoring des Ã©vÃ©nements
- [ ] DÃ©tection automatique de doublons
- [ ] API GraphQL pour les requÃªtes frontend
- [ ] Websockets pour les mises Ã  jour temps rÃ©el
- [ ] Docker pour le dÃ©ploiement

## ğŸ“§ Support

Pour toute question ou problÃ¨me :
1. VÃ©rifier les logs dans `/cron/logs/`
2. Consulter cette documentation
3. Tester avec `manual-scrape.php --test`

---

*Culture Radar - SystÃ¨me de scraping automatique v1.0*